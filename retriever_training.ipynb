{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from read_docx import read_docx\n",
    "file_path = 'data/Raptor Contract.docx'\n",
    "file = read_docx(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "615 senteneces were found\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Splitting the essay on '.', '?', and '!'\n",
    "single_sentences_list = re.split(r'(?<=[.?!])\\s+', file)\n",
    "print (f\"{len(single_sentences_list)} senteneces were found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "615 sentences were found\n",
      "Minimum sentence length: 4 characters\n",
      "Maximum sentence length: 6774 characters\n",
      "Average sentence length: 346.6292682926829 characters\n",
      "Standard deviation of sentence lengths: 467.06121471929816\n",
      "Variance of sentence lengths: 218146.17829506635\n",
      "Median sentence length: 226 characters\n",
      "Mode sentence length: 12 characters\n",
      "25th percentile sentence length: 92.5 characters\n",
      "50th percentile sentence length: 226.0 characters\n",
      "75th percentile sentence length: 431.5 characters\n",
      "90th percentile sentence length: 738.6000000000006 characters\n",
      "Skewness of sentence lengths: 5.845544492005728\n",
      "Kurtosis of sentence lengths: 62.621796477530324\n",
      "Interquartile range (IQR) of sentence lengths: 339.0\n",
      "Coefficient of variation (CV) of sentence lengths: 134.743732697415%\n",
      "Range of sentence lengths: 6770 characters\n",
      "median absolute deviation of sentence lengths: 170.0 characters\n"
     ]
    }
   ],
   "source": [
    "from read_docx import read_docx\n",
    "import re\n",
    "import statistics\n",
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "file_path = 'data/Raptor Contract.docx'\n",
    "file = read_docx(file_path)\n",
    "\n",
    "# Splitting the essay on '.', '?', and '!'\n",
    "single_sentences_list = re.split(r'(?<=[.?!])\\s+', file)\n",
    "print(f\"{len(single_sentences_list)} sentences were found\")\n",
    "\n",
    "# Calculate the lengths of all sentences\n",
    "sentence_lengths = [len(sentence) for sentence in single_sentences_list]\n",
    "\n",
    "min_length = min(sentence_lengths)\n",
    "max_length = max(sentence_lengths)\n",
    "average_length = sum(sentence_lengths) / len(single_sentences_list)\n",
    "std_deviation = statistics.stdev(sentence_lengths)\n",
    "variance = statistics.variance(sentence_lengths)\n",
    "median_length = statistics.median(sentence_lengths)\n",
    "mode_length = statistics.mode(sentence_lengths)\n",
    "percentile_25 = np.percentile(sentence_lengths, 25)\n",
    "percentile_50 = np.percentile(sentence_lengths, 50)\n",
    "percentile_75 = np.percentile(sentence_lengths, 75)\n",
    "percentile_90 = np.percentile(sentence_lengths, 90)\n",
    "\n",
    "# Calculate advanced statistics\n",
    "skewness = stats.skew(sentence_lengths)\n",
    "kurtosis = stats.kurtosis(sentence_lengths)\n",
    "iqr = np.percentile(sentence_lengths, 75) - np.percentile(sentence_lengths, 25)\n",
    "cv = (std_deviation / average_length) * 100\n",
    "data_range = max_length - min_length\n",
    "mad = np.median(np.abs(sentence_lengths - np.median(sentence_lengths)))\n",
    "\n",
    "print(f\"Minimum sentence length: {min_length} characters\")\n",
    "print(f\"Maximum sentence length: {max_length} characters\")\n",
    "print(f\"Average sentence length: {average_length} characters\")\n",
    "print(f\"Standard deviation of sentence lengths: {std_deviation}\")\n",
    "print(f\"Variance of sentence lengths: {variance}\")\n",
    "print(f\"Median sentence length: {median_length} characters\")\n",
    "print(f\"Mode sentence length: {mode_length} characters\")\n",
    "print(f\"25th percentile sentence length: {percentile_25} characters\")\n",
    "print(f\"50th percentile sentence length: {percentile_50} characters\")\n",
    "print(f\"75th percentile sentence length: {percentile_75} characters\")\n",
    "print(f\"90th percentile sentence length: {percentile_90} characters\")\n",
    "print(f\"Skewness of sentence lengths: {skewness}\")\n",
    "print(f\"Kurtosis of sentence lengths: {kurtosis}\")\n",
    "print(f\"Interquartile range (IQR) of sentence lengths: {iqr}\")\n",
    "print(f\"Coefficient of variation (CV) of sentence lengths: {cv}%\")\n",
    "print(f\"Range of sentence lengths: {data_range} characters\")\n",
    "print(f\"median absolute deviation of sentence lengths: {mad} characters\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Next step is to devise a formula to calculate optimal buffersize for our pipeline \n",
    "\n",
    "The optimal buffersize depends more on the central tendency and the dispersion of the data so \n",
    "\n",
    "the formula will use Mean, Mean Absolute deviation, the interquartile range, the skewness and \n",
    "\n",
    "finally kurtosis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the optimal buffer size of 1480 for \"Raptor Contract Document\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [{'sentence': x, 'index' : i} for i, x in enumerate(single_sentences_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_sentences(sentences, buffer_size=1):\n",
    "    # Go through each sentence dict\n",
    "    for i in range(len(sentences)):\n",
    "\n",
    "        # Create a string that will hold the sentences which are joined\n",
    "        combined_sentence = ''\n",
    "\n",
    "        # Add sentences before the current one, based on the buffer size.\n",
    "        for j in range(i - buffer_size, i):\n",
    "            # Check if the index j is not negative (to avoid index out of range like on the first one)\n",
    "            if j >= 0:\n",
    "                # Add the sentence at index j to the combined_sentence string\n",
    "                combined_sentence += sentences[j]['sentence'] + ' '\n",
    "\n",
    "        # Add the current sentence\n",
    "        combined_sentence += sentences[i]['sentence']\n",
    "\n",
    "        # Add sentences after the current one, based on the buffer size\n",
    "        for j in range(i + 1, i + 1 + buffer_size):\n",
    "            # Check if the index j is within the range of the sentences list\n",
    "            if j < len(sentences):\n",
    "                # Add the sentence at index j to the combined_sentence string\n",
    "                combined_sentence += ' ' + sentences[j]['sentence']\n",
    "\n",
    "        # Then add the whole thing to your dict\n",
    "        # Store the combined sentence in the current sentence dict\n",
    "        sentences[i]['combined_sentence'] = combined_sentence\n",
    "\n",
    "    return sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = combine_sentences(sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value of standard diviation indicates there is high variation in the length of senteces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings.sentence_transformer import (\n",
    "    SentenceTransformerEmbeddings,\n",
    ")\n",
    "from langchain_community.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use sentence transformer embedder for to minimize repetitive embedding using api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/w/Contract-Advisor-RAG-Towards-Building-A-High-Precision-Legal-Expert-LLM-APP-1/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "modules.json: 100%|██████████| 349/349 [00:00<00:00, 758kB/s]\n",
      "config_sentence_transformers.json: 100%|██████████| 116/116 [00:00<00:00, 310kB/s]\n",
      "README.md: 100%|██████████| 10.7k/10.7k [00:00<00:00, 8.55MB/s]\n",
      "sentence_bert_config.json: 100%|██████████| 53.0/53.0 [00:00<00:00, 140kB/s]\n",
      "config.json: 100%|██████████| 612/612 [00:00<00:00, 2.89MB/s]\n",
      "pytorch_model.bin: 100%|██████████| 90.9M/90.9M [02:34<00:00, 587kB/s]\n",
      "tokenizer_config.json: 100%|██████████| 350/350 [00:00<00:00, 539kB/s]\n",
      "vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 541kB/s]\n",
      "tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 491kB/s]\n",
      "special_tokens_map.json: 100%|██████████| 112/112 [00:00<00:00, 235kB/s]\n",
      "1_Pooling/config.json: 100%|██████████| 190/190 [00:00<00:00, 391kB/s]\n"
     ]
    }
   ],
   "source": [
    "oaiembeds = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'combined_sentence'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m oaiembeds\u001b[38;5;241m.\u001b[39membed_documents([x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcombined_sentence\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m sentences])\n",
      "Cell \u001b[0;32mIn[41], line 1\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m oaiembeds\u001b[38;5;241m.\u001b[39membed_documents([\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcombined_sentence\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m sentences])\n",
      "\u001b[0;31mKeyError\u001b[0m: 'combined_sentence'"
     ]
    }
   ],
   "source": [
    "embeddings = oaiembeds.embed_documents([x['combined_sentence'] for x in sentences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'page_content'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# load it into Chroma\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m db \u001b[38;5;241m=\u001b[39m \u001b[43mChroma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moaiembeds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Contract-Advisor-RAG-Towards-Building-A-High-Precision-Legal-Expert-LLM-APP-1/venv/lib/python3.10/site-packages/langchain_community/vectorstores/chroma.py:776\u001b[0m, in \u001b[0;36mChroma.from_documents\u001b[0;34m(cls, documents, embedding, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[1;32m    745\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    746\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_documents\u001b[39m(\n\u001b[1;32m    747\u001b[0m     \u001b[38;5;28mcls\u001b[39m: Type[Chroma],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    756\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    757\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Chroma:\n\u001b[1;32m    758\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create a Chroma vectorstore from a list of documents.\u001b[39;00m\n\u001b[1;32m    759\u001b[0m \n\u001b[1;32m    760\u001b[0m \u001b[38;5;124;03m    If a persist_directory is specified, the collection will be persisted there.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    774\u001b[0m \u001b[38;5;124;03m        Chroma: Chroma vectorstore.\u001b[39;00m\n\u001b[1;32m    775\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 776\u001b[0m     texts \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[1;32m    777\u001b[0m     metadatas \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[1;32m    778\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_texts(\n\u001b[1;32m    779\u001b[0m         texts\u001b[38;5;241m=\u001b[39mtexts,\n\u001b[1;32m    780\u001b[0m         embedding\u001b[38;5;241m=\u001b[39membedding,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    788\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    789\u001b[0m     )\n",
      "File \u001b[0;32m~/Contract-Advisor-RAG-Towards-Building-A-High-Precision-Legal-Expert-LLM-APP-1/venv/lib/python3.10/site-packages/langchain_community/vectorstores/chroma.py:776\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    745\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    746\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_documents\u001b[39m(\n\u001b[1;32m    747\u001b[0m     \u001b[38;5;28mcls\u001b[39m: Type[Chroma],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    756\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    757\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Chroma:\n\u001b[1;32m    758\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create a Chroma vectorstore from a list of documents.\u001b[39;00m\n\u001b[1;32m    759\u001b[0m \n\u001b[1;32m    760\u001b[0m \u001b[38;5;124;03m    If a persist_directory is specified, the collection will be persisted there.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    774\u001b[0m \u001b[38;5;124;03m        Chroma: Chroma vectorstore.\u001b[39;00m\n\u001b[1;32m    775\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 776\u001b[0m     texts \u001b[38;5;241m=\u001b[39m [\u001b[43mdoc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpage_content\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[1;32m    777\u001b[0m     metadatas \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[1;32m    778\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_texts(\n\u001b[1;32m    779\u001b[0m         texts\u001b[38;5;241m=\u001b[39mtexts,\n\u001b[1;32m    780\u001b[0m         embedding\u001b[38;5;241m=\u001b[39membedding,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    788\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    789\u001b[0m     )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'page_content'"
     ]
    }
   ],
   "source": [
    "# load it into Chroma\n",
    "db = Chroma.from_documents(sentences, oaiembeds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
